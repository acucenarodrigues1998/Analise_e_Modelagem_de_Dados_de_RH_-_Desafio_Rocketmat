{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HR Dataset Machine Learning - Desafio Rocketmat 02 e Desafio extra\n",
    "\n",
    "Esse notebook corresponde aos desafios 2 e extra da prova prática do processo seletivo para Estagiário em Ciência de Dados. Nele constam algumas propostas de problemas passíveis de ser resolvidos utilizando abordagens de machine learning e alguns experimentos realizados acerca de dois desses problemas e a interpretação dos modelos propostos.\n",
    "\n",
    "O dataset utilizado traz dados sobre o RH de uma empresa. O dados podem ser encontrados no kaggle através do link a seguir: https://www.kaggle.com/krismurphy01/data-lab\n",
    "\n",
    "A partir da observação dos dados disponível e das correlações, foi possível identificar alguns problemas que podem ser resolvidos utilizando técnincas de machine learning. Sendo eles:\n",
    "\n",
    "* Previsão de saída do funcionário\n",
    "* Previsão de desempenho do funcionário.\n",
    "* Previsão de funcionários aptos a promoção. (descartado)\n",
    "* Previsão de identificação entre o funcionário e a empresa (descartado).\n",
    "* Previsão de estresse com base em batimentos cardíacos (Não realizado). Dados de referência: https://www.tuasaude.com/frequencia-cardiaca/\n",
    "\n",
    "Desses, foram desenvolvidos experimentos para o problema de classificação para a previsão de saída de funcionários e um problema de regressão para prever a avaliação de desempenho de funcionários. \n",
    "\n",
    "Para o problema de classificação foram utilizadas árvores de decisão, random forest e o classificador SVC, trazendo duas abordagens para o mesmo problema. Como avaliação dos métodos foram utilizadas a Acurácia, o Kappa e a Área sobre a curva ROC. Para o problema de regressão foram utilizados os algoritimos de regressão linear, o regressor SVR e as árvores de decisão para regressão. A métrica utilizada foi o erro médio quadrado. Mais detalhes sobre essas aplicações serão mostrados mais a frente durante a experimentação. \n",
    "\n",
    "Os problemas seleção de funcionários (1) aptos a receberem uma promoção e de previsão da identificação do funcionário com a vaga (2) foram abandonados pelos seguintes motivos:\n",
    "* Para o problema 1, os dados são extremamente desbalanceados, sendo que poucas amostras de pessoas que foram promovidas. Poderiam ser utilizadas algumas técnicas de balanceamento, entretanto, um aumento de dados na quantidade que seria necessária seria muito ruim para os resultados, uma vez que para aumentar utilizaríamos algum algoritmo para a criação de dados falsos com base nos dados presentes no dataset e esses dados falsos em excesso poderiam prejudicar na avaliação, poderiam não condizer com a realidade dos dados. Outra técnica seria um downsample, ou seja, selecionar da classe majoritária, aleatoriamente, a mesma quantidade de amostras da classe minoritária. Entretanto, essa segunda abordagem resultaria em uma quantidade mínima de amostras que seriam insuficientes para treinar os modelos. \n",
    "* Ainda no problema 1, as variáveis preditoras disponíveis para resolver o problema são insuficiente. Eu realizei o teste com os classificadores citados acima e obtive um resultado extremamente insatisfatório. \n",
    "* O problema 2 se trata de uma classificação multiclasse, cujo o resultado, com os dados disponíveis, não chegou a 50%. Talvez a disponibilidade de mais algumas variáveis de satisfação e de desempenho melhorassem o resultado. \n",
    "\n",
    "O problema de previsão de estresse ainda não foi avaliado nesse projeto, eu apenas fiz algumas pesquisas relacionadas ao tema. \n",
    "\n",
    "Essas propostas foram resolvidas utilizando abordagens simples para a seleção de features, entretanto, poderia ter sido utilizado algum método de redução de dimensionalidade como o PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação de Pacotes e visualização inicial dos dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix, cohen_kappa_score, roc_auc_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "pd.set_option('display.max_columns', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./HR_data_to_ML.csv')\n",
    "data.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversão de variáveis categóricas\n",
    "\n",
    "Algoritmos de machine learning não lidam muito bem com dados categóricos. Para trabalhar com esse tipo de dado é necessário realizar um processo de conversão desses dados, transformando o valor em texto da variável em etiquetas numéricas. Para tal, foi utilizado o algoritmo LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_mask = data.dtypes==object\n",
    "categorical_cols = data.columns[categorical_feature_mask].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = data[categorical_cols]\n",
    "enc = LabelEncoder()\n",
    "data[categorical_cols] = data[categorical_cols].apply(enc.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a discretização dos valores, os dados categóricos ficaram assim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[categorical_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com esse tratamento feito, podemos rever aquelas correlações da primeira parte desse projeto para selecionar as features que melhor se relacionam com o problema e os modelos propostos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando as correlações para selecionar boas features para os problemas\n",
    "\n",
    "Aqui visualizamos as correlações. Para os problemas que serão resolvidos, precisamos procurar as features que melhor se relacionam com os targets desses problemas. Sendo que para a previsão de funcionários que sairão da empresa, a variável alvo é a coluna **left_Company** e para o problema da avaliação de desempenho, a variável alvo é a coluna **last_evaluation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(15, 12))\n",
    "    ax = sns.heatmap(corr, mask=mask, vmax=.3, square=True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ponto a ser comentado aqui é o fato de que as variáveis categóricas não estão tão bem correlacionadas com as demais variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 01: Prevendo a saída de um funcionário\n",
    "\n",
    "Aqui apresentamos o nosso primeiro experimento com uso de machine learning. \n",
    "\n",
    "A primeira coisa a ser avaliada é a distribuição entre as classes e com isso podemos notar que o dataset está bem desbalanceado, mas, realizei o experimento mesmo assim, até pra ter um resultado de base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.left_Company.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esse problema, eu realizei 2 experimentos. No primeiro, eu selecionei apenas as variáveis que possuíam algum grau de correlação incluindo a variável **EMP_Engagement_Mean** que possui uma correlação negativa igual a 1, o que significa que os nosso modelos irão atingir um resultado máximo. Esse teste foi feito apenas para visualizar como essa correlação forte se comporta nos modelos. O conjunto de dados foi dividido em subsets de treino e teste em uma proporção de 70% para treino e 30% para teste. Como o dataset é grande, essa proporção resulta em quantidades de dados satisfatórias para cada conjunto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['left_Company']\n",
    "X = data[['Emp_Identity', 'Emp_Role', 'Emp_Position', 'Emp_Title', 'EMP_Engagement_Mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro teste realizado foi utilizando uma árvore de decisão, abaixo são mostradas as etapas de treino, teste e avaliação do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "y_predict_tree = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Avaliação do modelo DecisionTreeClassifier\")\n",
    "print(\"Acurácia: {}\".format(tree.score(X_test, y_test)))\n",
    "print(\"Kappa: {}\".format(cohen_kappa_score(y_test, y_predict_tree)))\n",
    "print(\"Área sobre a curva ROC: {}\".format(roc_auc_score(y_test, y_predict_tree)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vemos a matriz de confusão do modelo, servindo mais como uma forma visual de analizar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(tree, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esperado, o modelo obteve 100% em todas as métricas utilizadas e como já foi dito antes, isso se deve principalmente a variável de engajamento que possui uma forte correlação com a variável alvo desse problema. Isso pode ser analisado verificando o feature importance do modelo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X.columns\n",
    "feature_imp = tree.feature_importances_\n",
    "pd.DataFrame({'Feature': columns,\n",
    "              'Importance': feature_imp},\n",
    "                columns=['Feature', 'Importance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com a correlação, por ser negativa, e com essa informação do modelo, uma interpretação provável para esse problema é que o principal fator responsável pela demissão/saída de um funcionário é o engajamento e a participação dele em atividades da empresa. Quanto menos engajado nas atividades, maiores são as chances de um funcionário deixar a empresa.\n",
    "\n",
    "Abaixo os testes com o RandomForest utilizando 10 estimadores e o SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict_rf = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Avaliação do modelo RandomForestClassifier\")\n",
    "print(\"Acurácia: {}\".format(rf.score(X_test, y_test)))\n",
    "print(\"Kappa: {}\".format(cohen_kappa_score(y_test, y_predict_rf)))\n",
    "print(\"Área sobre a curva ROC: {}\".format(roc_auc_score(y_test, y_predict_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rf, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso do Random Forest, as demais variáveis possuem alguma importância na definição do modelo, apesar de que aqui também a variável **EMP_Engagement_Mean** é a mais importante para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X.columns\n",
    "feature_imp = rf.feature_importances_\n",
    "pd.DataFrame({'Feature': columns,\n",
    "              'Importance': feature_imp},\n",
    "                columns=['Feature', 'Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "y_predict_svc = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Avaliação do modelo SVC\")\n",
    "print(\"Acurácia: {}\".format(svc.score(X_test, y_test)))\n",
    "print(\"Kappa: {}\".format(cohen_kappa_score(y_test, y_predict_svc)))\n",
    "print(\"Área sobre a curva ROC: {}\".format(roc_auc_score(y_test, y_predict_svc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(svc, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No classsificador SVC, utilizando o Kernel linear, também obtemos que a variável de engajamento é a mais importante. O SVC não possui as feature importance, mas possui os coeficientes que indicam os pesos que modelo deu para cada feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X.columns\n",
    "feature_imp = svc.coef_[0]\n",
    "pd.DataFrame({'Feature': columns,\n",
    "              'Importance': feature_imp},\n",
    "                columns=['Feature', 'Importance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, uma tabela resumindo os resultados obtidos pelos 3 modelos criados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Classificador': ['DecisionTree', 'RandomForestClassifier', 'SVC'], \n",
    "              'Acuracia': [tree.score(X_test, y_test), rf.score(X_test, y_test), svc.score(X_test, y_test)],\n",
    "              'Kappa': [cohen_kappa_score(y_test, y_predict_tree), cohen_kappa_score(y_test, y_predict_rf), cohen_kappa_score(y_test, y_predict_svc)],\n",
    "              'ROC_AUC': [roc_auc_score(y_test, y_predict_tree), roc_auc_score(y_test, y_predict_rf), roc_auc_score(y_test, y_predict_svc)]},\n",
    "              columns=['Classificador', 'Acuracia', 'Kappa', 'ROC_AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base no que foi observado acima, resolvi aplicar os mesmos testes para todos os dados do conjunto. Entretanto, a variável **EMP_Engagement_Mean** será eliminada do conjuntos. Com isso verificaremos os efeitos das outras features no modelo desconsiderando essa que já sabíamos que daria um excelente resultado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['left_Company']\n",
    "X = data.drop(['left_Company', 'EMP_Engagement_Mean'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "y_predict_tree = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Avaliação do modelo DecisionTreeClassifier\")\n",
    "print(\"Acurácia: {}\".format(tree.score(X_test, y_test)))\n",
    "print(\"Kappa: {}\".format(cohen_kappa_score(y_test, y_predict_tree)))\n",
    "print(\"Área sobre a curva ROC: {}\".format(roc_auc_score(y_test, y_predict_tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(tree, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X.columns\n",
    "feature_imp = tree.feature_importances_\n",
    "pd.DataFrame({'Feature': columns,\n",
    "              'Importance': feature_imp},\n",
    "                columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict_rf = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Avaliação do modelo RandomForestClassifier\")\n",
    "print(\"Acurácia: {}\".format(rf.score(X_test, y_test)))\n",
    "print(\"Kappa: {}\".format(cohen_kappa_score(y_test, y_predict_rf)))\n",
    "print(\"Área sobre a curva ROC: {}\".format(roc_auc_score(y_test, y_predict_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rf, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X.columns\n",
    "feature_imp = rf.feature_importances_\n",
    "pd.DataFrame({'Feature': columns,\n",
    "              'Importance': feature_imp},\n",
    "                columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "y_predict_svc = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Avaliação do modelo SVC\")\n",
    "print(\"Acurácia: {}\".format(svc.score(X_test, y_test)))\n",
    "print(\"Kappa: {}\".format(cohen_kappa_score(y_test, y_predict_svc)))\n",
    "print(\"Área sobre a curva ROC: {}\".format(roc_auc_score(y_test, y_predict_svc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({'Classificador': ['DecisionTree', 'RandomForestClassifier', 'SVC'], \n",
    "                           'Acuracia': [tree.score(X_test, y_test), rf.score(X_test, y_test), svc.score(X_test, y_test)],\n",
    "                           'Kappa': [cohen_kappa_score(y_test, y_predict_tree), cohen_kappa_score(y_test, y_predict_rf), cohen_kappa_score(y_test, y_predict_svc)],\n",
    "                           'ROC_AUC': [roc_auc_score(y_test, y_predict_tree), roc_auc_score(y_test, y_predict_rf), roc_auc_score(y_test, y_predict_svc)]},\n",
    "                            columns=['Classificador', 'Acuracia', 'Kappa', 'ROC_AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 02: Prevendo o desempenho de um funcionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['last_evaluation']\n",
    "X = data[['number_project', 'average_montly_hours', 'Percent_Remote', 'Emp_Identity', 'Emp_Role', 'Emp_Position', 'Emp_Title', 'Sensor_StepCount', 'Sensor_Heartbeat(Average/Min)', 'EMP_Engagement_Mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "y_pred = svr.predict(X_test)\n",
    "mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_r = DecisionTreeRegressor()\n",
    "tree_r.fit(X_train, y_train)\n",
    "y_pred = tree_r.predict(X_test)\n",
    "mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
